"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[674],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>g});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),m=c(n),p=a,g=m["".concat(l,".").concat(p)]||m[p]||d[p]||o;return n?r.createElement(g,i(i({ref:t},u),{},{components:n})):r.createElement(g,i({ref:t},u))}));function g(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[m]="string"==typeof e?e:a,i[1]=s;for(var c=2;c<o;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},2591:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var r=n(7462),a=(n(7294),n(3905));const o={slug:"recommendations-current23",title:"Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka",authors:["matthias"],tags:["AI","Kafka","Flink","Postgres","microservice","DataSQRL"]},i=void 0,s={permalink:"/blog/recommendations-current23",editUrl:"https://github.com/DataSQRL/datasqrl.github.io/edit/main/blog/2023-09-21-recommendations-current23-ai.md",source:"@site/blog/2023-09-21-recommendations-current23-ai.md",title:"Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka",description:"Let\u2019s build a personalized recommendation engine using AI as an event-driven microservice with Kafka, Flink, and Postgres. And since Current23 is starting soon, we will use the events of this event-driven conference as our input data (sorry for the pun). You\u2019ll learn how to apply AI techniques to streaming data and what talks you want to attend at the Kafka conference - double win!",date:"2023-09-21T00:00:00.000Z",formattedDate:"September 21, 2023",tags:[{label:"AI",permalink:"/blog/tags/ai"},{label:"Kafka",permalink:"/blog/tags/kafka"},{label:"Flink",permalink:"/blog/tags/flink"},{label:"Postgres",permalink:"/blog/tags/postgres"},{label:"microservice",permalink:"/blog/tags/microservice"},{label:"DataSQRL",permalink:"/blog/tags/data-sqrl"}],readingTime:10.755,hasTruncateMarker:!0,authors:[{name:"Matthias Broecheler",title:"CEO of DataSQRL",url:"https://github.com/mbroecheler",imageURL:"/img/headshots/matthias1.png",key:"matthias"}],frontMatter:{slug:"recommendations-current23",title:"Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka",authors:["matthias"],tags:["AI","Kafka","Flink","Postgres","microservice","DataSQRL"]},nextItem:{title:"To Preprocess or to Query, that\u2019s the Question!",permalink:"/blog/preprocess-or-query"}},l={authorsImageUrls:[void 0]},c=[],u={toc:c},m="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(m,(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("head",null,(0,a.kt)("meta",{property:"og:image",content:"/img/blog/recommendationsCurrent23.png"}),(0,a.kt)("meta",{name:"twitter:image",content:"/img/blog/recommendationsCurrent23.png"})),(0,a.kt)("p",null,"Let\u2019s build a personalized recommendation engine using AI as an event-driven microservice with Kafka, Flink, and Postgres. And since Current23 is starting soon, we will use the events of this event-driven conference as our input data (sorry for the pun). You\u2019ll learn how to apply AI techniques to streaming data and what talks you want to attend at the Kafka conference - double win!"),(0,a.kt)("p",null,"We will implement the whole microservice in 50 lines of code thanks to the DataSQRL compiler, which eliminates all the data plumbing so we can focus on building."),(0,a.kt)("img",{src:"/img/blog/recommendationsCurrent23.png",alt:"Build AI Recommendations with DataSQRL >|",width:"40%"}),(0,a.kt)("h1",{id:"what-we-will-build"},"What We Will Build"),(0,a.kt)("p",null,"We are going to build a recommendation engine and semantic search that uses AI to provide personalized results for users based on user interactions."),(0,a.kt)("p",null,"Let\u2019s break that down:\nOur input data is a stream of conference events, namely the talks with title, abstract, speakers, time, and so forth. We consume this data from an external data source."),(0,a.kt)("p",null,"In addition, our microservice has endpoints to capture which talks a user has liked and what interests a user has expressed. We use those user interactions to create a semantic user profile for personalized recommendations and personalized search results."),(0,a.kt)("p",null,"We create the semantic user profile through vector embeddings, an AI technique for mapping text to numbers in a way that preserves the content of the text for comparison. It\u2019s a great tool for representing the meaning of text in a computable way. It's like mapping addresses (i.e. street, city, zip, country) onto geo-coordinates. It\u2019s hard to compare two addresses, but easy to compute the distance between two geo-coordinates. Vector embeddings do the same thing for natural language text."),(0,a.kt)("p",null,"Those semantic profiles are then used to serve recommendations and personalized search results."))}d.isMDXComponent=!0}}]);