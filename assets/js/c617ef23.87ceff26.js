"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4596],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>h});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),u=d(n),p=r,h=u["".concat(l,".").concat(p)]||u[p]||m[p]||i;return n?a.createElement(h,s(s({ref:t},c),{},{components:n})):a.createElement(h,s({ref:t},c))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,s=new Array(i);s[0]=p;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[u]="string"==typeof e?e:r,s[1]=o;for(var d=2;d<i;d++)s[d]=n[d];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},7683:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var a=n(7462),r=(n(7294),n(3905));const i={slug:"recommendations-current23",title:"Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka",authors:["matthias"],tags:["AI","Kafka","Flink","Postgres","microservice","DataSQRL"]},s=void 0,o={permalink:"/blog/recommendations-current23",editUrl:"https://github.com/DataSQRL/datasqrl.github.io/edit/main/blog/2023-09-21-recommendations-current23-ai.md",source:"@site/blog/2023-09-21-recommendations-current23-ai.md",title:"Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka",description:"Let\u2019s build a personalized recommendation engine using AI as an event-driven microservice with Kafka, Flink, and Postgres. And since Current23 is starting soon, we will use the events of this event-driven conference as our input data (sorry for the pun). You\u2019ll learn how to apply AI techniques to streaming data and what talks you want to attend at the Kafka conference - double win!",date:"2023-09-21T00:00:00.000Z",formattedDate:"September 21, 2023",tags:[{label:"AI",permalink:"/blog/tags/ai"},{label:"Kafka",permalink:"/blog/tags/kafka"},{label:"Flink",permalink:"/blog/tags/flink"},{label:"Postgres",permalink:"/blog/tags/postgres"},{label:"microservice",permalink:"/blog/tags/microservice"},{label:"DataSQRL",permalink:"/blog/tags/data-sqrl"}],readingTime:10.755,hasTruncateMarker:!0,authors:[{name:"Matthias Broecheler",title:"CEO of DataSQRL",url:"https://github.com/mbroecheler",imageURL:"/img/headshots/matthias1.png",key:"matthias"}],frontMatter:{slug:"recommendations-current23",title:"Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka",authors:["matthias"],tags:["AI","Kafka","Flink","Postgres","microservice","DataSQRL"]},nextItem:{title:"To Preprocess or to Query, that\u2019s the Question!",permalink:"/blog/preprocess-or-query"}},l={authorsImageUrls:[void 0]},d=[{value:"Imports",id:"imports",level:2},{value:"Processing Event Data",id:"processing-event-data",level:2},{value:"Processing User Interactions",id:"processing-user-interactions",level:2},{value:"User Analytics",id:"user-analytics",level:2},{value:"Personalized Recommendation",id:"personalized-recommendation",level:2},{value:"Personalized Search",id:"personalized-search",level:2}],c={toc:d},u="wrapper";function m(e){let{components:t,...n}=e;return(0,r.kt)(u,(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("head",null,(0,r.kt)("meta",{property:"og:image",content:"/img/blog/recommendationsCurrent23.png"}),(0,r.kt)("meta",{name:"twitter:image",content:"/img/blog/recommendationsCurrent23.png"})),(0,r.kt)("p",null,"Let\u2019s build a personalized recommendation engine using AI as an event-driven microservice with Kafka, Flink, and Postgres. And since Current23 is starting soon, we will use the events of this event-driven conference as our input data (sorry for the pun). You\u2019ll learn how to apply AI techniques to streaming data and what talks you want to attend at the Kafka conference - double win!"),(0,r.kt)("p",null,"We will implement the whole microservice in 50 lines of code thanks to the DataSQRL compiler, which eliminates all the data plumbing so we can focus on building."),(0,r.kt)("img",{src:"/img/blog/recommendationsCurrent23.png",alt:"Build AI Recommendations with DataSQRL >|",width:"40%"}),(0,r.kt)("h1",{id:"what-we-will-build"},"What We Will Build"),(0,r.kt)("p",null,"We are going to build a recommendation engine and semantic search that uses AI to provide personalized results for users based on user interactions."),(0,r.kt)("p",null,"Let\u2019s break that down:\nOur input data is a stream of conference events, namely the talks with title, abstract, speakers, time, and so forth. We consume this data from an external data source."),(0,r.kt)("p",null,"In addition, our microservice has endpoints to capture which talks a user has liked and what interests a user has expressed. We use those user interactions to create a semantic user profile for personalized recommendations and personalized search results."),(0,r.kt)("p",null,"We create the semantic user profile through vector embeddings, an AI technique for mapping text to numbers in a way that preserves the content of the text for comparison. It\u2019s a great tool for representing the meaning of text in a computable way. It's like mapping addresses (i.e. street, city, zip, country) onto geo-coordinates. It\u2019s hard to compare two addresses, but easy to compute the distance between two geo-coordinates. Vector embeddings do the same thing for natural language text."),(0,r.kt)("p",null,"Those semantic profiles are then used to serve recommendations and personalized search results. "),(0,r.kt)("p",null,"To summarize, our microservice will expose the following API (expressed in GraphQL schema):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},"type Mutation {\n    Likes(liked: LikedInput!): LikeAdded\n    AddInterest(interest: AddInterest!): InterestAdded\n}\n\ntype Query {\n    Events(limit: Int!, offset: Int = 0): [Events!]!\n    EventsLiked(userid: String!): [EventsLiked!]!\n    RecommendedEvents(userid: String!): [RecommendedEvents!]\n    PersonalizedEventSearch(query: String!, userid: String!): [PersonalizedEventSearch!]\n}\n")),(0,r.kt)("p",null,"The API has two mutations (for REST folks, think of those as POST): one captures which events a user has liked, and another captures a user\u2019s interests."),(0,r.kt)("p",null,"We have four query endpoints (those are like GET): two boring ones that return all the events and the events a user has liked and two AI-powered ones that return recommended events for a user and personalized search results for a user\u2019s search query."),(0,r.kt)("p",null,"You can see the full GraphQL API with the mutation and return types ",(0,r.kt)("a",{parentName:"p",href:"https://gist.github.com/mbroecheler/bd3ba8a8307fc36836a91599b9ff2643"},"here"),"."),(0,r.kt)("h1",{id:"architecture"},"Architecture"),(0,r.kt)("p",null,"We will implement our conference recommendation service as an event-driven microservice for robust, real-time processing at scale. The architecture of the microservice is shown below and uses Kafka for event storage, Flink for stream processing, Postgres for querying, and GraphQL for the API."),(0,r.kt)("img",{src:"/img/blog/current23_microservice.svg",alt:"Event-driven microservice architecture >",width:"60%"}),(0,r.kt)("p",null,"The data travels counter-clockwise from the top:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"When a user interaction is captured through the mutation endpoint,"),(0,r.kt)("li",{parentName:"ol"},"the input data is written to Kafka as an event, "),(0,r.kt)("li",{parentName:"ol"},"which gets picked up by Flink, processed, embedded as a vector, and aggregated into a semantic user profile, "),(0,r.kt)("li",{parentName:"ol"},"which is stored in Postgres. "),(0,r.kt)("li",{parentName:"ol"},"When a user requests data through the query endpoint, the data is fetched from Postgres. "),(0,r.kt)("li",{parentName:"ol"},"In addition, the conference events are ingested by Flink from an external data source and similarly processed and stored in the database for querying.")),(0,r.kt)("p",null,"Each component serves a distinct purpose in this event-driven architecture: the GraphQL server acts as the interface to the outside world, Kafka manages events in motion, Flink processes the event stream, and Postgres stores the processed data for retrieval on request."),(0,r.kt)("h1",{id:"implementation"},"Implementation"),(0,r.kt)("p",null,"Now, we could implement this event-driven microservice by implementing each of the components: implement the GraphQL server, set up the Kafka topics and event schemas, implement a Flink job for data processing, and design a database schema plus SQL queries. We would have to write a ton of data plumbing code: moving data between systems, mapping schemas, designing data models, and stitching it all together. There is a reason event-driven microservices are built by teams of specialists."),(0,r.kt)("p",null,"There is a better way: We are going to use the open-source DataSQRL compiler to generate all of that data plumbing code for us. That means we can implement our entire microservice in just 50 lines of SQL code as follows (",(0,r.kt)("a",{parentName:"p",href:"https://gist.github.com/mbroecheler/315f99fc53768f579014ab9be7cc2fd4"},"click here")," to see the entire SQL script):"),(0,r.kt)("h2",{id:"imports"},"Imports"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"IMPORT conference.Events;  --import external data\nIMPORT recAPI.Likes;        --import data from API mutation\nIMPORT recAPI.AddInterest;  --import data from API mutation\n\nIMPORT string.*;\nIMPORT text.*;\nIMPORT vector.*;\nIMPORT time.parseTimestamp;\n")),(0,r.kt)("p",null,"We import the source tables that we are processing in this script. DataSQRL uses packages to represent data sources for modularity and ease of reuse. It\u2019s like importing an external library but for data.\nOur API is treated as a data source which allows us to import the mutation input data as a table."),(0,r.kt)("p",null,"We are also importing functions for string processing, vector embedding, etc. DataSQRL uses the same packaging structure to organize functions."),(0,r.kt)("p",null,"Now, onto the actual logic of our script."),(0,r.kt)("h2",{id:"processing-event-data"},"Processing Event Data"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"Events.id := coalesce(CAST(regexExtract(url, '(\\d*)$') AS INT),0);\nEvents.full_text := concat(title,'\\n',abstract);\nEvents.startTime := concat(trim(regexExtract(date, '^[^-]*')),' ',trim(regexExtract(time, '\\d\\d?:\\d\\d\\s(AM|PM)')));\nEvents.startTimestamp := parseTimestamp(concat(startTime,' PDT'), 'MMMM d, yyyy h:mm a z')\nEvents.embedding := onnxEmbed(full_text, '/build/embedding/model_quantized.onnx');\n\nEvents := DISTINCT Events ON id ORDER BY last_updated DESC;\n")),(0,r.kt)("p",null,"First, we are adding additional columns to the ",(0,r.kt)("inlineCode",{parentName:"p"},"Events")," table and then deduplicating the data stream so we have the most recent version of each event."),(0,r.kt)("p",null,"We are adding columns mostly to clean up our ingested events data. When you are dealing with external data, cleanup is often necessary. In this case, we need to do some work to extract the event timestamp and id."),(0,r.kt)("p",null,"We are also adding the ",(0,r.kt)("inlineCode",{parentName:"p"},"embedding")," column to compute a vector embedding for the ",(0,r.kt)("inlineCode",{parentName:"p"},"title")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"abstract")," of each talk. We are using the ",(0,r.kt)("a",{parentName:"p",href:"https://onnxruntime.ai/"},"ONNX AI")," runtime to execute the embedding model. The embedding model we are using here is a quantized version of the ",(0,r.kt)("a",{parentName:"p",href:"https://www.sbert.net/docs/pretrained_models.html"},"all-MiniLM-L6-v2")," pre-trained model. This is a model for sentence embedding trained on a large corpus that is small and fast while delivering good performance. \u201cQuantized\u201d means that the model has been transformed to run efficiently on CPUs for those of us who aren\u2019t hoarding GPUs right now."),(0,r.kt)("h2",{id:"processing-user-interactions"},"Processing User Interactions"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"AddInterest.embedding := onnxEmbed(text, '/build/embedding/model_quantized.onnx');\n\nLikeVector := SELECT l.userid, e.embedding, l._source_time\n              FROM Likes l TEMPORAL JOIN Events e ON l.eventId = e.id WHERE l.liked;\n\nUserInterestVectors := \n    (SELECT userid, embedding, _source_time FROM LikeVector)\n        UNION ALL\n    (SELECT userid, embedding, _source_time FROM AddInterest)\n\nUserInterests := SELECT userid, center(embedding) as interestVector \n                 FROM UserInterestVectors GROUP BY userid;\n")),(0,r.kt)("p",null,"Next, we are processing the user interactions. We are adding an embedding vector for the user interests captured in the AddInterst table. We are joining the user ",(0,r.kt)("inlineCode",{parentName:"p"},"Likes")," with the deduplicated events table using a ",(0,r.kt)("a",{parentName:"p",href:"../temporal-join"},"temporal join")," to get the embedding vector for the liked event. Both of those capture the semantic interests of a user."),(0,r.kt)("p",null,"Then, we combine those data streams in the ",(0,r.kt)("inlineCode",{parentName:"p"},"UserInterstVectors")," table and aggregate them by computing the centroid for all those vectors for each user. That summary of user interest vectors gives us the semantic profile of each user."),(0,r.kt)("h2",{id:"user-analytics"},"User Analytics"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"UserLikes := DISTINCT Likes ON userid, eventId ORDER BY _source_time DESC;\n\nEventLikeCount := SELECT eventid, count(*) as num, avg(eventid) as test\n                  FROM UserLikes l WHERE l.liked GROUP BY eventid;\n\nEvents.likeCount := JOIN EventLikeCount l ON @.id = l.eventid;\n\nEventsLiked(@userid: String) := \n    SELECT e.* FROM UserLikes l JOIN Events e ON l.eventId = e.id\n    WHERE l.userid = @userid\n    ORDER BY e.startTimestamp ASC;\n")),(0,r.kt)("p",null,"To show you that DataSQRL also supports good old-fashioned data analytics, we are adding some user likes analytics. We deduplicate the stream of ",(0,r.kt)("inlineCode",{parentName:"p"},"Likes")," (in case a user liked and then unliked an event) and aggregate them by event into the ",(0,r.kt)("inlineCode",{parentName:"p"},"EventLikeCount")," table."),(0,r.kt)("p",null,"We add a relationship between ",(0,r.kt)("inlineCode",{parentName:"p"},"Events")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"EventLikeCount")," so that the like count can be accessed from the event through the API. DataSQRL adds relationships to SQL, so you can structure your data for API access and to simplify join expressions."),(0,r.kt)("p",null,"We add a table function that returns all the events a user has liked which maps onto the query endpoint in the GraphQL API of the same name."),(0,r.kt)("h2",{id:"personalized-recommendation"},"Personalized Recommendation"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"RecommendedEvents(@userid: String) :=\n    SELECT e.*, cosineSimilarity(i.interestVector, e.embedding) as score\n    FROM UserInterests i JOIN Events e\n    WHERE i.userid = @userid ORDER BY score DESC;\n")),(0,r.kt)("p",null,"To serve users personalized recommendations, we compute the similarity between the event embedding and the aggregated semantic user profile of the ",(0,r.kt)("inlineCode",{parentName:"p"},"UserInterests")," table using cosine similarity between the vectors."),(0,r.kt)("h2",{id:"personalized-search"},"Personalized Search"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"PersonalizedEventSearch(@query: String, @userid: String) :=\n    SELECT e.*, coalesce(cosineSimilarity(i.interestVector, e.embedding),0.0) as score\n    FROM Events e LEFT JOIN UserInterests i ON i.userid = @userid\n    WHERE textsearch(@query, title, abstract) > 0\n    ORDER BY score DESC;\n")),(0,r.kt)("p",null,"For personalized search, we retrieve those events where the title or abstract matches the search query and then rank the results based on how similar the event is to the aggregated user interests."),(0,r.kt)("h1",{id:"conclusion"},"Conclusion"),(0,r.kt)("p",null,"And that\u2019s it. A complete event-driven microservice with vector embedding, personalized search, and user interaction analytics in 50 lines of SQL code."),(0,r.kt)("p",null,"And DataSQRL handles all the rest: mapping mutations onto Kafka topics and events, ingesting those events into Flink and mapping schemas, designing the physical data models in Kafka, Flink, and the database, mapping API calls onto database queries, optimizing index structures, and moving the data efficiently between all those components. That\u2019s a whole lot of soul-sucking work we did not have to do."),(0,r.kt)("p",null,"If you want to learn more about DataSQRL, visit ",(0,r.kt)("a",{parentName:"p",href:"/"},"datasqrl.com"),", take a look at the ",(0,r.kt)("a",{parentName:"p",href:"/docs/getting-started/intro/overview/"},"in-depth tutorial"),", or ",(0,r.kt)("a",{parentName:"p",href:"/community"},"join the community")," on ",(0,r.kt)("a",{parentName:"p",href:"https://discord.gg/49AnhVY2w9"},"Discord")," to ask questions and share your thoughts and feedback."),(0,r.kt)("h1",{id:"run-microservice"},"Run Microservice"),(0,r.kt)("p",null,"Want to run the recommendation microservice yourself? It\u2019s easy. Follow these steps:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"In your command line, create an empty folder and go into the folder:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir current23; cd current23\n")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Download the SQRL script, GraphQL schema, vector embedding model and event data source by ",(0,r.kt)("a",{parentName:"p",href:"https://drive.google.com/file/d/15p6erQnG8S4eDVgjxiOdYEfvqdEgjc0M/view?usp=sharing"},"clicking here"),", moving the zip file into folder you just created and unpacking it. You should see 3 directories (conference, conferencedata, and embedding) as well as a ",(0,r.kt)("inlineCode",{parentName:"p"},"sqrl")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"graphqls")," file. The SQRL script and GraphQL schema are the ones we walked through above.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Compile the SQRL script and GraphQL schema into an event-driven microservice by running:"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker run --rm -v $PWD:/build datasqrl/cmd:dev compile conference-recommendation.sqrl recAPI.graphqls --mnt $PWD\n")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Disclaimer: We are using the preview release of DataSQRL to showcase the vector embedding feature that's coming in the next release.\nUse the latest tag for the stable release.")),(0,r.kt)("ol",{start:4},(0,r.kt)("li",{parentName:"ol"},"Stand up the entire microservice in docker by running:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"(cd build/deploy; docker compose up)\n")),(0,r.kt)("p",null,"Note, that the microservice does not contain DataSQRL. DataSQRL is only the compiler and generates the docker-compose script for orchestrating the microservice. The microservice itself only consists of Kafka, Flink, Postgres, and GraphQL server.\nIf you want to take a look at the deployment artifacts that DataSQRL compiled for each component, take a peek inside the ",(0,r.kt)("inlineCode",{parentName:"p"},"build/deploy")," folder."),(0,r.kt)("p",null,"Once the microservice is up and running (it takes a little while for all the components to boot up and initialize), the GraphQL API is accessible. You can access the API directly or open ",(0,r.kt)("a",{parentName:"p",href:"http://localhost:8888/graphiql/"},"http://localhost:8888/graphiql/")," to try out queries in your browser."),(0,r.kt)("p",null,"For example, run this query to get a list of events."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},"{\n    Events(limit:20) {\n        id\n        title\n        abstract\n        time\n        location\n    }\n}\n")),(0,r.kt)("p",null,"Add a user interest by running the following mutation:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},"mutation AddInterest($interest: AddInterest!) {\n  AddInterest(interest: $interest) {\n  _source_time\n}}\n")),(0,r.kt)("p",null,'And add the following query payload under "Query Variables":'),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "interest": {\n    "userid": "1234",\n    "text": "I want to learn more about Apache Flink and how to use it for real-time stream processing."\n  }\n}\n')),(0,r.kt)("p",null,"Then look at the recommendations for the user ",(0,r.kt)("inlineCode",{parentName:"p"},"1234"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'{\n  RecommendedEvents(userid: "1234") {\n    id\n    title\n    abstract\n  }\n}\n')),(0,r.kt)("p",null,"You can like an event with this mutation:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},"mutation AddLike($liked: LikedInput!) {\n  Likes(liked: $liked) {\n  _source_time\n}}\n")),(0,r.kt)("p",null,"and this payload:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "liked": {\n    "userid": "1234",\n    "eventId": 1136822,\n    "liked": true\n  }\n}\n')),(0,r.kt)("p",null,"And then see how that impacts the personalized search results with this query:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'{\n  PersonalizedEventSearch(query: "kafka", userid: "1234") {\n    id\n    title\n    abstract\n  }\n}\n')),(0,r.kt)("p",null,"As you can see, our search results are strongly biased in the direction of Apache Flink since that's what we liked a Flink talk and expressed an interest in Flink."),(0,r.kt)("p",null,"Enjoy playing with the API and finding the talks you want to attend at the conference."),(0,r.kt)("p",null,"To shut the microservice down, hit CTRL-C and then run ",(0,r.kt)("inlineCode",{parentName:"p"},"(cd build/deploy; docker compose down -v)")," to remove the volumes."))}m.isMDXComponent=!0}}]);