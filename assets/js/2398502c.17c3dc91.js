"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8085],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>h});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=p(a),d=i,h=m["".concat(s,".").concat(d)]||m[d]||u[d]||o;return a?n.createElement(h,r(r({ref:t},c),{},{components:a})):n.createElement(h,r({ref:t},c))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:i,r[1]=l;for(var p=2;p<o;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},649:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var n=a(7462),i=(a(7294),a(3905));const o={slug:"simplifying-flink-app-development",title:"Simplifying Apache Flink Application Development with DataSQRL",authors:["matthias"],tags:["DataSQRL","Flink"]},r="Simplifying Apache Flink Application Development with DataSQRL",l={permalink:"/blog/simplifying-flink-app-development",editUrl:"https://github.com/DataSQRL/datasqrl.github.io/edit/main/blog/2023-06-21-simplifying-flink-app-development.md",source:"@site/blog/2023-06-21-simplifying-flink-app-development.md",title:"Simplifying Apache Flink Application Development with DataSQRL",description:"Apache Flink is an incredibly powerful stream processor. But to build a complete application with Flink you need to integrate multiple complex technologies which requires a significant amount of custom code.",date:"2023-06-21T00:00:00.000Z",formattedDate:"June 21, 2023",tags:[{label:"DataSQRL",permalink:"/blog/tags/data-sqrl"},{label:"Flink",permalink:"/blog/tags/flink"}],readingTime:4.46,hasTruncateMarker:!0,authors:[{name:"Matthias Broecheler",title:"CEO of DataSQRL",url:"https://github.com/mbroecheler",imageURL:"/img/headshots/matthias1.png",key:"matthias"}],frontMatter:{slug:"simplifying-flink-app-development",title:"Simplifying Apache Flink Application Development with DataSQRL",authors:["matthias"],tags:["DataSQRL","Flink"]},prevItem:{title:"Why Apache Flink and GraphQL Are like Peanut Butter and Jelly",permalink:"/blog/flink-graphql-peanut-butter-jelly"},nextItem:{title:"SQRL: Enhancing SQL to a High-Level Data Language",permalink:"/blog/sqrl-high-level-data-language-sql"}},s={authorsImageUrls:[void 0]},p=[{value:"The Challenge of Building Applications with Flink",id:"the-challenge-of-building-applications-with-flink",level:2},{value:"Introducing DataSQRL: A Solution for Streamlined Flink Development",id:"introducing-datasqrl-a-solution-for-streamlined-flink-development",level:2},{value:"DataSQRL Does the Work for You",id:"datasqrl-does-the-work-for-you",level:2}],c={toc:p},m="wrapper";function u(e){let{components:t,...a}=e;return(0,i.kt)(m,(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Apache Flink is an incredibly powerful stream processor. But to build a complete application with Flink you need to integrate multiple complex technologies which requires a significant amount of custom code.\nDataSQRL is an open-source tool that simplifies this process by compiling SQL into a data pipeline that integrates Flink, Kafka, Postgres, and API layer. "),(0,i.kt)("div",{style:{float:"right",width:"40%"}},(0,i.kt)("iframe",{width:"100%",height:"100%",src:"https://www.youtube.com/embed/mf5q-IdbVQY",title:"DataSQRL Introduction",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0})),(0,i.kt)("p",null,"DataSQRL allows you to focus on your application logic without getting bogged down in the details of how to execute your data transformations efficiently across multiple technologies."),(0,i.kt)("h2",{id:"the-challenge-of-building-applications-with-flink"},"The Challenge of Building Applications with Flink"),(0,i.kt)("p",null,"We have built several applications in Flink: recommendation engines, data mesh endpoints, monitoring dashboards, Customer 360 APIs, smart IoT apps, and more. Across those use cases, Flink proved to be versatile and powerful in its ability to instantly analyze and aggregate data from multiple sources. But we found it quite difficult and time-consuming to build applications with Flink."),(0,i.kt)("img",{src:"/img/reference/compiledMicroservice.svg",alt:"DataSQRL compiled data pipeline >",width:"50%"}),(0,i.kt)("p",null,"To start, you need to learn Flink: the table and datastream API, watermarking, windowing, and all the other stream processing concepts. Flink alone gets our heads spinning. And Flink is just one component of the application."),(0,i.kt)("p",null,"To build a complete data pipeline, you need Kafka to hold your streaming data and a database like Postgres to query the processed data. On top, you need an API layer that captures input data and provides access to the processed data. Your team must learn, implement, and integrate multiple complex technologies. It takes a village to build a Flink app."),(0,i.kt)("h2",{id:"introducing-datasqrl-a-solution-for-streamlined-flink-development"},"Introducing DataSQRL: A Solution for Streamlined Flink Development"),(0,i.kt)("img",{src:"/img/full_squirrel.svg",alt:"DataSQRL >",width:"20%"}),(0,i.kt)("p",null,"That\u2019s why we built ",(0,i.kt)("a",{parentName:"p",href:"/"},"DataSQRL"),". DataSQRL compiles the SQL that defines your data processing into an integrated data pipeline that orchestrates Flink, Kafka, Postgres, and API - saving us a ton of time and headache in the process. Why not let the computer do all the hard work?"),(0,i.kt)("p",null,"Let me show you how DataSQRL works by building an IoT monitoring service."),(0,i.kt)("p",null,"First, we implement the data processing for our monitoring service in SQL."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql",metastring:"title=metrics.sqrl",title:"metrics.sqrl"},"IMPORT datasqrl.example.sensors.SensorReading; -- Import sensor data\nIMPORT time.endOfSecond;  -- Import time function\n/* Aggregate sensor readings to second */\nSecReading := SELECT sensorid, endOfSecond(time) as timeSec,\n                     avg(temperature) as temp FROM SensorReading\n              GROUP BY sensorid, timeSec;\n/* Get max temperature in last minute */\nSensorMaxTemp := SELECT sensorid, max(temp) as maxTemp\n                 FROM SecReading\n                 WHERE timeSec >= now() - INTERVAL 1 MINUTE\n                 GROUP BY sensorid;\n")),(0,i.kt)("p",null,"This script imports the metrics stream which are temperature readings collected by sensors. DataSQRL treats external data sources like software dependencies that you import, allowing the compiler to handle configuration management, data mapping, and schema evolution for us. We also import a time function we\u2019ll use for aggregation."),(0,i.kt)("p",null,"Then we define two tables: The first table smoothes out the readings by taking the average temperature each second. The SensorMaxTemp table computes the maximum temperature for each sensor over the last minute."),(0,i.kt)("p",null,"Next, we are going to define the API for our monitoring service.  That\u2019s how users of our service query the data.\nThe API is defined by a GraphQL schema. It specifies the query endpoints and result types."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-graphql",metastring:"title=metricsapi.graphqls",title:"metricsapi.graphqls"},"type Query {\n    SecReading(sensorid: Int!): [SecReading!]\n    SensorMaxTemp(sensorid: Int): [SensorMaxTemp!]\n}\n\n\ntype SecReading {\n    sensorid: Int!\n    timeSec: String!\n    temp: Float!\n}\n\n\ntype SensorMaxTemp {\n    sensorid: Int!\n    maxTemp: Float!\n}\n")),(0,i.kt)("p",null,"Note, how the tables map to query endpoints and types. That\u2019s how it all fits together."),(0,i.kt)("p",null,"And don\u2019t worry, you don\u2019t have to write this schema - DataSQRL can generate it for you from the SQL script."),(0,i.kt)("p",null,"DataSQRL compiles the script and GraphQL schema into an integrated data pipeline with the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"docker run --rm -v $PWD:/build datasqrl/cmd compile metrics.sqrl metricsapi.graphqls\n")),(0,i.kt)("p",null,"It also generates a docker-compose template to stand up the entire service."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"(cd build/deploy; docker compose up)\n")),(0,i.kt)("p",null,"We can now interact with the API and try it out by opening ",(0,i.kt)("a",{parentName:"p",href:"http://localhost:8888/graphiql/?query=query%20MaxTemp%20%7B%0A%20%20SensorMaxTemp%20%7B%0A%20%20%20%20sensorid%0A%20%20%20%20maxTemp%0A%20%20%7D%0A%7D%0A&operationName=MaxTemp"},"http://localhost:8888/graphiql/"),"."),(0,i.kt)("h2",{id:"datasqrl-does-the-work-for-you"},"DataSQRL Does the Work for You"),(0,i.kt)("p",null,"Pretty simple, right? And the best part is that DataSQRL compiles deployment artifacts for each component that you can inspect and deploy anywhere. There is no magic or black box.\nFor example, DataSQRL compiles a Flink jar you can execute on an existing Flink cluster or Flink managed service."),(0,i.kt)("img",{src:"/img/generic/undraw_launch.svg",alt:"DataSQRL Does the Work >",width:"30%"}),(0,i.kt)("p",null,"Most importantly, consider all the work we didn\u2019t have to do. No data source configuration, watermark setting, Kafka integration, database schema definition, index structure selection, API implementation, and so on. DataSQRL compiles all that for you."),(0,i.kt)("p",null,"DataSQRL also supports inserts to ingest events, subscriptions to push data updates in real-time to the client, and exporting data to Kafka topics or downstream systems. Take a look at the ",(0,i.kt)("a",{parentName:"p",href:"/docs/getting-started/quickstart"},"Quickstart tutorial")," which shows you how to do that - it only takes a few minutes."),(0,i.kt)("p",null,"DataSQRL is an ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/DataSQRL/sqrl"},"open-source project"),". If you like the idea of DataSQRL, have questions, or need help building your streaming application, ",(0,i.kt)("a",{parentName:"p",href:"/community"},"don\u2019t hesitate to reach out"),"."),(0,i.kt)("p",null,"To sum up, DataSQRL is a tool for simplifying the development of Apache Flink applications by automating the integration of various technologies and allowing developers to focus on their application logic. It makes Flink accessible to lazy developers like us."),(0,i.kt)("p",null,"Have fun building applications with Flink!"))}u.isMDXComponent=!0}}]);