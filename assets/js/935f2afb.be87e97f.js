"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"link","label":"Overview","href":"/docs/intro","docId":"intro"},{"type":"category","label":"Getting Started","collapsed":false,"items":[{"type":"link","label":"Quickstart Tutorial","href":"/docs/getting-started/quickstart","docId":"getting-started/quickstart"},{"type":"category","label":"DataSQRL Introduction","items":[{"type":"link","label":"Implement SQRL Script","href":"/docs/getting-started/intro/sqrl","docId":"getting-started/intro/sqrl"},{"type":"link","label":"Connect Data Source","href":"/docs/getting-started/intro/data-sources","docId":"getting-started/intro/data-sources"},{"type":"link","label":"Design the API","href":"/docs/getting-started/intro/api","docId":"getting-started/intro/api"},{"type":"link","label":"Advanced Concepts","href":"/docs/getting-started/intro/advanced","docId":"getting-started/intro/advanced"},{"type":"link","label":"DataSQRL Compiler","href":"/docs/getting-started/intro/compiler","docId":"getting-started/intro/compiler"}],"collapsed":true,"collapsible":true,"href":"/docs/getting-started/intro/overview"},{"type":"link","label":"What is DataSQRL?","href":"/docs/getting-started/concepts/datasqrl","docId":"getting-started/concepts/datasqrl"},{"type":"link","label":"What is SQRL?","href":"/docs/getting-started/concepts/sqrl","docId":"getting-started/concepts/sqrl"},{"type":"link","label":"Why Use DataSQRL?","href":"/docs/getting-started/concepts/why-datasqrl","docId":"getting-started/concepts/why-datasqrl"},{"type":"link","label":"When to use DataSQRL","href":"/docs/getting-started/comparison/overview","docId":"getting-started/comparison/overview"},{"type":"category","label":"DataSQRL Tutorials","items":[{"type":"link","label":"Recommendations","href":"/docs/getting-started/tutorials/recommendations/intro","docId":"getting-started/tutorials/recommendations/intro"},{"type":"link","label":"Internet of Things","href":"/docs/getting-started/tutorials/iot/intro","docId":"getting-started/tutorials/iot/intro"}],"collapsed":true,"collapsible":true,"href":"/docs/getting-started/tutorials/overview"}],"collapsible":true,"href":"/docs/getting-started/overview"},{"type":"category","label":"Reference Documentation","items":[{"type":"category","label":"SQRL","items":[{"type":"link","label":"Table","href":"/docs/reference/sqrl/table","docId":"reference/sqrl/table"},{"type":"link","label":"Relationship","href":"/docs/reference/sqrl/relationship","docId":"reference/sqrl/relationship"},{"type":"link","label":"Stream Table","href":"/docs/reference/sqrl/stream","docId":"reference/sqrl/stream"},{"type":"link","label":"Time","href":"/docs/reference/sqrl/time","docId":"reference/sqrl/time"},{"type":"link","label":"Import","href":"/docs/reference/sqrl/import","docId":"reference/sqrl/import"},{"type":"link","label":"Export","href":"/docs/reference/sqrl/export","docId":"reference/sqrl/export"},{"type":"category","label":"Functions","items":[{"type":"link","label":"String Functions","href":"/docs/reference/sqrl/functions/string","docId":"reference/sqrl/functions/string"},{"type":"link","label":"Time Functions","href":"/docs/reference/sqrl/functions/time","docId":"reference/sqrl/functions/time"},{"type":"link","label":"Implement Custom Functions","href":"/docs/reference/sqrl/functions/custom-functions","docId":"reference/sqrl/functions/custom-functions"}],"collapsed":true,"collapsible":true,"href":"/docs/category/functions"},{"type":"link","label":"SQL Primer","href":"/docs/reference/sqrl/sql-primer","docId":"reference/sqrl/sql-primer"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/sqrl/overview"},{"type":"category","label":"API","items":[{"type":"category","label":"GraphQL","items":[{"type":"link","label":"Query","href":"/docs/reference/api/graphql/query","docId":"reference/api/graphql/query"},{"type":"link","label":"Design","href":"/docs/reference/api/graphql/design","docId":"reference/api/graphql/design"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/api/graphql/design"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/api/overview"},{"type":"category","label":"Sources & Sinks","items":[{"type":"link","label":"Add Source/Sink","href":"/docs/reference/sources/discovery","docId":"reference/sources/discovery"},{"type":"category","label":"Data System","items":[{"type":"link","label":"File System","href":"/docs/reference/sources/system/file","docId":"reference/sources/system/file"},{"type":"link","label":"Apache Kafka","href":"/docs/reference/sources/system/kafka","docId":"reference/sources/system/kafka"},{"type":"link","label":"Print","href":"/docs/reference/sources/system/print","docId":"reference/sources/system/print"}],"collapsed":true,"collapsible":true,"href":"/docs/category/data-system"},{"type":"category","label":"Data Format","items":[{"type":"link","label":"JSON","href":"/docs/reference/sources/format/json","docId":"reference/sources/format/json"},{"type":"link","label":"CSV","href":"/docs/reference/sources/format/csv","docId":"reference/sources/format/csv"},{"type":"link","label":"AVRO","href":"/docs/reference/sources/format/avro","docId":"reference/sources/format/avro"}],"collapsed":true,"collapsible":true,"href":"/docs/category/data-format"},{"type":"link","label":"DataSQRL Schema","href":"/docs/reference/sources/schema","docId":"reference/sources/schema"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/sources/overview"},{"type":"category","label":"Build","items":[{"type":"link","label":"Command Reference","href":"/docs/reference/operations/command","docId":"reference/operations/command"},{"type":"link","label":"Repository","href":"/docs/reference/operations/repository","docId":"reference/operations/repository"},{"type":"link","label":"Optimizer","href":"/docs/reference/operations/optimizer","docId":"reference/operations/optimizer"},{"type":"link","label":"Package Configuration","href":"/docs/reference/operations/package-config","docId":"reference/operations/package-config"},{"type":"link","label":"Deploy","href":"/docs/reference/operations/deploy/overview","docId":"reference/operations/deploy/overview"},{"type":"category","label":"Engines","items":[{"type":"link","label":"Flink","href":"/docs/reference/operations/engines/flink","docId":"reference/operations/engines/flink"},{"type":"link","label":"Postgres","href":"/docs/reference/operations/engines/postgres","docId":"reference/operations/engines/postgres"},{"type":"link","label":"Vertx","href":"/docs/reference/operations/engines/vertx","docId":"reference/operations/engines/vertx"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/operations/engines/overview"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/operations/build"},{"type":"category","label":"Key Concepts","items":[{"type":"link","label":"Package","href":"/docs/reference/concepts/package","docId":"reference/concepts/package"},{"type":"link","label":"Data Service","href":"/docs/reference/concepts/data-service","docId":"reference/concepts/data-service"},{"type":"link","label":"Data Pipeline","href":"/docs/reference/concepts/data-pipeline","docId":"reference/concepts/data-pipeline"}],"collapsed":true,"collapsible":true,"href":"/docs/category/key-concepts"}],"collapsed":true,"collapsible":true,"href":"/docs/reference/overview"},{"type":"category","label":"Developer Documentation","items":[{"type":"link","label":"Architecture","href":"/docs/dev/architecture","docId":"dev/architecture"},{"type":"link","label":"Roadmap","href":"/docs/dev/roadmap","docId":"dev/roadmap"},{"type":"link","label":"How to Contribute","href":"/docs/dev/contribute","docId":"dev/contribute"}],"collapsed":true,"collapsible":true,"href":"/docs/dev/overview"},{"type":"category","label":"DataSQRL Process","items":[{"type":"link","label":"Focus on the Customer","href":"/docs/process/customer-focused","docId":"process/customer-focused"},{"type":"link","label":"Embrace Change","href":"/docs/process/responsive","docId":"process/responsive"},{"type":"link","label":"Stay Aligned","href":"/docs/process/integrated","docId":"process/integrated"}],"collapsed":true,"collapsible":true,"href":"/docs/process/intro"}]},"docs":{"attribution":{"id":"attribution","title":"Image Attribution","description":"Throughout the website and documentation, we are using free images from third party sources to illustrate our content."},"dev/architecture":{"id":"dev/architecture","title":"Architecture","description":"DataSQRL is a compiler that produces fully integrated data pipelines.","sidebar":"docs"},"dev/contribute":{"id":"dev/contribute","title":"How to Contribute","description":"We appreciate your contribution to DataSQRL - together we can build something great.","sidebar":"docs"},"dev/mission":{"id":"dev/mission","title":"Mission and Goals","description":"WIP"},"dev/overview":{"id":"dev/overview","title":"Deep-Dive & Developer Documentation","description":"DataSQRL is an open-source project, which means you can view the entire source code, fork and customize it, and make contributions to the project.","sidebar":"docs"},"dev/roadmap":{"id":"dev/roadmap","title":"Roadmap","description":"DataSQRL is currently in developer preview. That means, there is enough","sidebar":"docs"},"getting-started/comparison/overview":{"id":"getting-started/comparison/overview","title":"When to use DataSQRL","description":"\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/concepts/datasqrl":{"id":"getting-started/concepts/datasqrl","title":"What is DataSQRL?","description":"DataSQRL is an open-source compiler and build tool for developing data services. A data service processes, transforms, or analyzes data from one or multiple sources (databases, data streams, file storage, etc.) and exposes the result through an API.","sidebar":"docs"},"getting-started/concepts/sqrl":{"id":"getting-started/concepts/sqrl","title":"What is SQRL?","description":"DataSQRL uses a declarative language called SQRL to express the logic and structure of a data service. You implement a data service in SQRL scripts by defining how to combine, transform, and analyze the input data through a sequence of SQL(ish) statements. DataSQRL compiles SQRL scripts into fully-integrated data pipelines and an API layer that serves the result.","sidebar":"docs"},"getting-started/concepts/why-datasqrl":{"id":"getting-started/concepts/why-datasqrl","title":"Why Use DataSQRL?","description":"We love building with data, but we got frustrated by how complicated it is to build data APIs. Why can you build a production-grade web service in a few days, but it takes months to build a mediocre data service that looks like Frankenstein on a bad hair day. We built DataSQRL to change that.","sidebar":"docs"},"getting-started/install":{"id":"getting-started/install","title":"Download & Install","description":"Work in progress - not ready yet"},"getting-started/intro/advanced":{"id":"getting-started/intro/advanced","title":"Advanced Concepts","description":"You have made it through the entire introduction tutorial and want to keep learning about DataSQLR? Kudos to you! This page highlights some additional aspects of DataSQRL with pointers to more information, so you can continue your journey to ninja SQRL status \ud83e\udd47.","sidebar":"docs"},"getting-started/intro/api":{"id":"getting-started/intro/api","title":"Design the API","description":"\\" width=\\"50%\\"/>","sidebar":"docs"},"getting-started/intro/compiler":{"id":"getting-started/intro/compiler","title":"DataSQRL Compiler","description":"You\'ve gone through the introductory tutorial and seen how DataSQRL compiles SQRL scripts and API specifications into end-to-end streaming data pipelines that ingest data, process it, and serve the results through an API.","sidebar":"docs"},"getting-started/intro/data-sources":{"id":"getting-started/intro/data-sources","title":"Connect Data Source","description":"\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/intro/overview":{"id":"getting-started/intro/overview","title":"DataSQRL Introduction","description":"|\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/intro/sqrl":{"id":"getting-started/intro/sqrl","title":"Implement SQRL Script","description":"\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/overview":{"id":"getting-started/overview","title":"Getting Started with DataSQRL","description":"Fantastic, you want to get started with DataSQRL and build streaming data APIs the fast and easy way. You\'ll be building data APIs successfully with DataSQLR in no time. How you get started is up to you. We recommend the \\"Learning by Doing\\" route, but you can choose your own adventure.","sidebar":"docs"},"getting-started/quickstart":{"id":"getting-started/quickstart","title":"Quickstart Tutorial","description":"|\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/tutorials/iot/intro":{"id":"getting-started/tutorials/iot/intro","title":"Internet of Things","description":"\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/tutorials/overview":{"id":"getting-started/tutorials/overview","title":"DataSQRL Tutorials","description":"The tutorials implement a use case with DataSQRL. We currently cover the following use cases:","sidebar":"docs"},"getting-started/tutorials/recommendations/intro":{"id":"getting-started/tutorials/recommendations/intro","title":"Recommendations","description":"\\" width=\\"40%\\"/>","sidebar":"docs"},"getting-started/tutorials/seedshop-protein":{"id":"getting-started/tutorials/seedshop-protein","title":"Protein Analysis for Happy Squirrels","description":"For our seed shop, we want to add"},"getting-started/tutorials/telco":{"id":"getting-started/tutorials/telco","title":"Telecommunications","description":""},"intro":{"id":"intro","title":"Overview","description":"\\" width=\\"40%\\"/>","sidebar":"docs"},"process/customer-focused":{"id":"process/customer-focused","title":"Focus on the Customer","description":"1: Focus on the Customer","sidebar":"docs"},"process/integrated":{"id":"process/integrated","title":"Stay Aligned","description":"3: Stay Aligned","sidebar":"docs"},"process/intro":{"id":"process/intro","title":"The DataSQRL Process","description":"Across many organizations, we observed that data service projects commonly struggle or fail because of:","sidebar":"docs"},"process/responsive":{"id":"process/responsive","title":"Embrace Change","description":"2: Embrace Change","sidebar":"docs"},"reference/api/graphql/design":{"id":"reference/api/graphql/design","title":"Design","description":"The easiest way to design your custom GraphQL data API with DataSQRL is to start with the GraphQL schema that is generated by the compiler.","sidebar":"docs"},"reference/api/graphql/query":{"id":"reference/api/graphql/query","title":"Query","description":"This page is work-in-progress as we add additional languages.","sidebar":"docs"},"reference/api/overview":{"id":"reference/api/overview","title":"Data API","description":"DataSQRL compiles a data API that exposes the data processed by your SQRL script.","sidebar":"docs"},"reference/concepts/data-pipeline":{"id":"reference/concepts/data-pipeline","title":"Data Pipeline","description":"A data pipeline is an automated, scalable system that facilitates the efficient flow, processing, and transformation of data from various sources to designated destinations like API endpoints or other data systems.","sidebar":"docs"},"reference/concepts/data-service":{"id":"reference/concepts/data-service","title":"Data Service","description":"A data service processes, transforms, or analyzes data from one or multiple sources and exposes the result through an API.","sidebar":"docs"},"reference/concepts/package":{"id":"reference/concepts/package","title":"Package","description":"A package is a grouping of files that the DataSQRL compiler can load at compile time to resolve external dependencies of an SQRL script. A package is represented by a directory on the local filesystem. DataSQRL locates the package directory relative to the build path.","sidebar":"docs"},"reference/concepts/view-store":{"id":"reference/concepts/view-store","title":"View Store","description":"(don\'t use - kept just for reference)"},"reference/operations/build":{"id":"reference/operations/build","title":"Build","description":"This page provides an overview of how to compile, run, and debug SQRL scripts and projects using the DataSQRL command.","sidebar":"docs"},"reference/operations/command":{"id":"reference/operations/command","title":"Command Reference","description":"You interact with DataSQRL through the DataSQRl command on your command line. The DataSQRL command compiles and runs SQRL scripts, discovers data sources and sinks, and publishes packages to the repository.","sidebar":"docs"},"reference/operations/deploy/aws":{"id":"reference/operations/deploy/aws","title":"Deploy on AWS","description":"This documentation walks you through the steps of deploying a data pipeline compiled by DataSQLR on AWS managed services. Using managed services eliminates most of the operational burden of running a data pipeline, auto-scales each engine based on the amount of incoming data and API workload, and gets you up and running with a production-grade data pipeline in an under an hour."},"reference/operations/deploy/github-action":{"id":"reference/operations/deploy/github-action","title":"Deploying to AWS lambda via Github Action","description":"Deploying to AWS lambda as a Github action for development validation."},"reference/operations/deploy/overview":{"id":"reference/operations/deploy/overview","title":"Deploy","description":"You can either deploy DataSQRL scripts in standalone mode or deploy each engine separately. Standalone mode is the easiest deployment option. Deploying each engine separately gives you greater control over the deployment, allows you to scale each engine independently with workload requirements, and is robust to failure.","sidebar":"docs"},"reference/operations/deploy/secrets":{"id":"reference/operations/deploy/secrets","title":"Secrets","description":""},"reference/operations/engines/flink":{"id":"reference/operations/engines/flink","title":"Flink","description":"Apache Flink is an open-source stream processing engine designed to process large volumes of real-time data with low latency and high throughput. Flink uses a distributed dataflow programming model to process data in parallel across a cluster of machines. Flink supports both batch and stream processing, allowing users to analyze both historical and real-time data with the same programming model. Flink also provides fault tolerance and high availability mechanisms, ensuring that data processing is resilient in the face of failures.","sidebar":"docs"},"reference/operations/engines/overview":{"id":"reference/operations/engines/overview","title":"DataSQRL Engines","description":"An engine is a system or technology that executes part of the data pipeline compiled by DataSQRL.","sidebar":"docs"},"reference/operations/engines/postgres":{"id":"reference/operations/engines/postgres","title":"Postgres","description":"Postgres is an open-source relational database management system (RDBMS) that emphasizes extensibility and compliance with SQL standards. Postgres offers a powerful set of data manipulation and analysis tools, including advanced indexing options, query optimization, and support for full-text search. In addition, it provides a robust security model with built-in authentication, authorization, and auditing capabilities. Postgres is widely used in enterprise and web-based applications, as well as in academic and scientific environments, and has a large and active user community that contributes to its ongoing development and improvement.","sidebar":"docs"},"reference/operations/engines/vertx":{"id":"reference/operations/engines/vertx","title":"Vertx","description":"Vert.x is a lightweight and flexible open-source framework for building reactive, event-driven applications in Java and other JVM languages. It provides a comprehensive toolkit for developing scalable and high-performance networked applications that can handle a large number of concurrent connections. The framework\'s key features include a non-blocking API that allows for efficient use of resources, a modular architecture that enables easy integration with other libraries, and a distributed event bus for communication between components.","sidebar":"docs"},"reference/operations/optimizer":{"id":"reference/operations/optimizer","title":"Optimizer","description":"The optimizer is part of the DataSQRL compiler and determines the optimal data pipeline to execute a SQRL script and serve a given API specification.","sidebar":"docs"},"reference/operations/package-config":{"id":"reference/operations/package-config","title":"Package Configuration","description":"The package configuration is the central configuration file used by the DataSQRL command. The package configuration declares dependencies, configures the engines in the data pipeline, sets compiler options, and provides package information.","sidebar":"docs"},"reference/operations/repository":{"id":"reference/operations/repository","title":"Repository","description":"A repository contains DataSQRL packages. When compiling an SQRL script, the DataSQRL compiler retrieves dependencies declared in the package configuration and unpacks them in the build directory.","sidebar":"docs"},"reference/overview":{"id":"reference/overview","title":"Reference Documentation","description":"The reference documentation covers all aspects of DataSQRL and the SQRL language in detail.","sidebar":"docs"},"reference/sources/discovery":{"id":"reference/sources/discovery","title":"Add Source/Sink","description":"Data discovery is the easiest way to connect a data source or sink to DataSQRL and add a data source/sink package.","sidebar":"docs"},"reference/sources/format/avro":{"id":"reference/sources/format/avro","title":"AVRO","description":"DataSQRL support for Avro is currently in the works and will be added shortly.","sidebar":"docs"},"reference/sources/format/csv":{"id":"reference/sources/format/csv","title":"CSV","description":"DataSQRL supports CSV as a data format.","sidebar":"docs"},"reference/sources/format/json":{"id":"reference/sources/format/json","title":"JSON","description":"DataSQRL supports JSON as a data format.","sidebar":"docs"},"reference/sources/overview":{"id":"reference/sources/overview","title":"Data Sources and Sinks","description":"Data sources and sinks are packages that contain configuration files for reading data from or writing data to external data systems. A data source/sink package is a set of tables. Each table represents a stream or static set of data in another system, such as a Kafka topic, a collection of files, a CDC stream of a database table, etc.","sidebar":"docs"},"reference/sources/schema":{"id":"reference/sources/schema","title":"DataSQRL Schema","description":"The DataSQRL schema is a flexible schema format for data sources and sinks. DataSQRL schema is simple, accommodates semi-structured data, supports schema evolution, and provides testing capabilities.","sidebar":"docs"},"reference/sources/system/file":{"id":"reference/sources/system/file","title":"File System","description":"The file data system reads and writes data from a file system. That can be a local or attached file system, a cloud file system like AWS S3, HDFS, or URLs.","sidebar":"docs"},"reference/sources/system/kafka":{"id":"reference/sources/system/kafka","title":"Apache Kafka","description":"DataSQRL supports Apache Kafka as a data source and data sink to ingest or export data stream.","sidebar":"docs"},"reference/sources/system/print":{"id":"reference/sources/system/print","title":"Print","description":"The print data sink prints the data records in a stream to standard output.","sidebar":"docs"},"reference/sources/trigger":{"id":"reference/sources/trigger","title":"Trigger Sinks","description":"A trigger sink is a sink that triggers an action for each record that is exported to the sink based on the data in the record. Actions that a sink can trigger include API calls, function invocations, and alerts."},"reference/sqrl/export":{"id":"reference/sqrl/export","title":"Export","description":"The EXPORT statement feeds records from a stream table to an external data system or action trigger in realtime.","sidebar":"docs"},"reference/sqrl/functions/custom-functions":{"id":"reference/sqrl/functions/custom-functions","title":"Implement Custom Functions","description":"A custom function package contains function definitions and implementations that the DataSQRL compiler can import into a script.","sidebar":"docs"},"reference/sqrl/functions/string":{"id":"reference/sqrl/functions/string","title":"String Functions","description":"The string function package contains functions to manipulate and analyze strings and characters. The string function package is part of the standard SQRL function library.","sidebar":"docs"},"reference/sqrl/functions/time":{"id":"reference/sqrl/functions/time","title":"Time Functions","description":"The time function package contains functions to convert, aggregate, and manipulate timestamps and DateTime scalars. The time function package is part of the standard SQRL function library.","sidebar":"docs"},"reference/sqrl/import":{"id":"reference/sqrl/import","title":"Import","description":"The IMPORT statements imports tables and functions into an SQRL script. Tables can either be imported from an external data source or another SQRL script.","sidebar":"docs"},"reference/sqrl/overview":{"id":"reference/sqrl/overview","title":"SQRL Documentation","description":"SQRL is a declarative language for defining data transformations based on SQL. SQRL stands for \\"Structured Query and Reaction Language\\" because it extends SQL with support for streaming data and the ability to react to data in realtime. In addition, SQRL adds a number of convenience features that make it development-friendly.","sidebar":"docs"},"reference/sqrl/relationship":{"id":"reference/sqrl/relationship","title":"Relationship","description":"SQRL supports relationship columns which relate a row in one table to rows in another table.","sidebar":"docs"},"reference/sqrl/sql-primer":{"id":"reference/sqrl/sql-primer","title":"SQL Primer","description":"SQL (Structured Query Language) is the standard query language used by relational database systems.","sidebar":"docs"},"reference/sqrl/stream":{"id":"reference/sqrl/stream","title":"Stream Table","description":"Stream tables contain immutable rows of data that have a timestamp. All tables imported from data sources are stream tables and stream tables can be exported to data sinks.","sidebar":"docs"},"reference/sqrl/table":{"id":"reference/sqrl/table","title":"Table","description":"The \\"table\\" is the central concept of SQRL. A table defines a set or stream of data. Every data record in SQRL is a row in a table. A table is defined by a list of columns which have unique column names.","sidebar":"docs"},"reference/sqrl/time":{"id":"reference/sqrl/time","title":"Time","description":"Time is an important concept in SQRL because it determines how data streams are processed.","sidebar":"docs"}}}')}}]);