<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Blog | DataSQRL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:url" content="https://www.datasqrl.com/blog/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data, API, SQRL, DataSQRL, data product, data pipeline, database, streaming, real-time analytics"><meta data-rh="true" name="twitter:card" content="summary"><meta data-rh="true" name="twitter:site" content="@DataSQRL"><meta data-rh="true" property="og:title" content="Blog | DataSQRL"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><meta data-rh="true" property="og:image" content="/img/dev/temporal_join.png"><meta data-rh="true" name="twitter:image" content="/img/dev/temporal_join.png"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.datasqrl.com/blog/"><link data-rh="true" rel="alternate" href="https://www.datasqrl.com/blog/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.datasqrl.com/blog/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="DataSQRL RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="DataSQRL Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y4XLW4QZYX"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-Y4XLW4QZYX",{})</script>



<link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/assets/css/styles.2a43d707.css">
<link rel="preload" href="/assets/js/runtime~main.f0548db5.js" as="script">
<link rel="preload" href="/assets/js/main.ae18b9cf.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/head_squirrel.svg" alt="DataSQRL Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/head_squirrel.svg" alt="DataSQRL Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">DataSQRL</b></a><a class="navbar__item navbar__link" href="/docs/intro/">Learn</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Use Cases</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/usecases/datamesh/">Data Mesh</a></li><li><a class="dropdown__link" href="/usecases/microservice/">Event-Driven Microservice</a></li><li><a class="dropdown__link" href="/usecases/ai/">Artifical Intelligence</a></li><li><a class="dropdown__link" href="/usecases/observability/">Observability &amp; Automation</a></li></ul></div><a class="navbar__item navbar__link" href="/community/">Community</a><a class="navbar__item navbar__link" href="/services/">Services</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog/">Blog</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/contact/">Contact Us</a><a href="https://github.com/DataSQRL/sqrl" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/acorn-agent-financial-use-cases/">How Acorn Agent Unlocks the Value of Your Business Data with GenAI</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/acorn-agent-announcement/">Acorn Agent Framework for Building LLM Applications</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/canz-joins-datasqrl/">Canz Joins DataSQRL</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/personalized-ai-search/">Personalized AI Search with Vector Embeddings for Semantic Profiles</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/recommendations-current23/">Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Have you wondered how companies can leverage their data through GenAI technologies for business growth? With the open-source Acorn Agent Framework, businesses can now extract actionable insights, enhance user engagement, and catalyze new revenue streams by using Generative AI technologies on their data. Acorn Agent enables Large Language Models (LLMs) to connect seamlessly with a company’s data via API calls, providing natural language access to complex sources of data. Let’s explore how Acorn Agent can unlock the value of your data, using financial services as an example."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/acorn-agent-financial-use-cases/">How Acorn Agent Unlocks the Value of Your Business Data with GenAI</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-08-05T00:00:00.000Z" itemprop="datePublished">August 5, 2024</time> · <!-- -->8 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/stefananca/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/stefan1.png" alt="Stefan Anca" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/stefananca/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Stefan Anca</span></a></div><small class="avatar__subtitle" itemprop="description">AI Consultant</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Have you wondered how companies can leverage their data through GenAI technologies for business growth? With the open-source <a href="https://github.com/DataSQRL/Acorn/" target="_blank" rel="noopener noreferrer"><strong>Acorn Agent Framework</strong></a>, businesses can now extract actionable insights, enhance user engagement, and catalyze new revenue streams by using Generative AI technologies on their data. Acorn Agent enables Large Language Models (LLMs) to connect seamlessly with a company’s data via API calls, providing natural language access to complex sources of data. Let’s explore how Acorn Agent can unlock the value of your data, using financial services as an example.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="unlocking-business-potential-with-acorn-agent">Unlocking Business Potential with Acorn Agent<a href="#unlocking-business-potential-with-acorn-agent" class="hash-link" aria-label="Direct link to Unlocking Business Potential with Acorn Agent" title="Direct link to Unlocking Business Potential with Acorn Agent">​</a></h2><p>Imagine a financial institution, such as a bank, which has extensive data on their users and their transactions. How can this data be used to drive additional business? Here are some examples that unlock the value of customer data through LLM Agents powered by Acorn Agent.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-developing-a-financial-assistant-chatbot">Step 1: Developing a Financial Assistant ChatBot<a href="#step-1-developing-a-financial-assistant-chatbot" class="hash-link" aria-label="Direct link to Step 1: Developing a Financial Assistant ChatBot" title="Direct link to Step 1: Developing a Financial Assistant ChatBot">​</a></h3><p>A Financial Assistant ChatBot that can retrieve user transactions and credit card history when responding to user questions and extract valuable insights about user spending. Having access to the user data, the Financial Assistant can perform tasks like:</p><ul><li><strong>Transaction Analysis</strong>: Which transactions accounted for most of my spending this month?</li><li><strong>Expense Breakdown</strong>: Show me a breakdown of my expenses per category for this month.</li><li><strong>Trend Identification</strong>: Highlight categories where my expenses increased from last month.</li></ul><img loading="lazy" src="/img/blog/acorn_financial_use_case.png" alt="Acorn Agent Financial Use Case &gt;" width="100%" class="img_ev3q"><p>By displaying information in natural language, tables and visual charts, this chatbot enables users to retrieve the information they need. This improves customer satisfaction and reduces customer support costs. And as users interact with the chatbot for insights and analytics, they use their bank accounts more, fostering loyalty and increasing user engagement.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/acorn/">acorn</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/gen-ai/">GenAI</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about How Acorn Agent Unlocks the Value of Your Business Data with GenAI" href="/blog/acorn-agent-financial-use-cases/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Large-Language Models (LLMs) provide a natural language interface capable of understanding user intent and delivering highly specific responses. The recent addition of &quot;tooling&quot; as a primary feature of LLMs has enabled them to retrieve information on-demand and trigger actions. This makes LLMs a viable natural language interface for various applications, including dashboards, ERPs, CRMs, BI systems, HRMS, SCM, and even customer-facing mobile and web applications. The Acorn Agent framework offers the infrastructure to build such LLM-powered applications by instrumenting LLMs with custom tooling in a safe, secure, and efficient manner. The Acorn Agent framework is open-source under the Apache 2.0 license."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/acorn-agent-announcement/">Acorn Agent Framework for Building LLM Applications</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-07-25T00:00:00.000Z" itemprop="datePublished">July 25, 2024</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/stefananca/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/stefan1.png" alt="Stefan Anca" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/stefananca/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Stefan Anca</span></a></div><small class="avatar__subtitle" itemprop="description">AI Consultant</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Large-Language Models (LLMs) provide a natural language interface capable of understanding user intent and delivering highly specific responses. The recent addition of &quot;tooling&quot; as a primary feature of LLMs has enabled them to retrieve information on-demand and trigger actions. This makes LLMs a viable natural language interface for various applications, including dashboards, ERPs, CRMs, BI systems, HRMS, SCM, and even customer-facing mobile and web applications. The Acorn Agent framework offers the infrastructure to build such LLM-powered applications by instrumenting LLMs with custom tooling in a safe, secure, and efficient manner. The Acorn Agent framework is open-source under the Apache 2.0 license.</p><img loading="lazy" src="/img/generic/acorn_agent_mascot.png" alt="Acorn Agent Mascot &gt;" width="30%" class="img_ev3q"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">​</a></h2><p>Large-Language Models are neural networks that process input text and incrementally generate intelligent responses. Advances in the size, topology, and training of LLMs increased their performance as conversational interfaces to near-human levels. To date, LLMs have been confined to chat and search applications, where they are trained on extensive corpora and augmented with query-specific information through methods such as RAG, FLARE, or text search.</p><p>The recent addition of &quot;tooling&quot; as a primary feature has broadened the applicability of LLMs. &quot;Tooling&quot; is a set of function definitions provided to the LLM either in-prompt or through training. The LLM can invoke these functions to retrieve information on demand (e.g., looking up the current weather) or trigger an external action (e.g., placing an order). This enables LLMs to interact with external systems and information outside the immediate user context. The LLM can invoke APIs, run database queries, execute computations, trigger UI updates, and more.</p><p>Tooling makes it possible to build conversational interfaces with LLMs for user facing applications that enable the user to interact naturally with the application through text or voice.
However, integrating LLMs with custom tooling poses several challenges:</p><ul><li><strong>Safety</strong>: LLMs are non-deterministic and prone to hallucinations, requiring careful validation and comprehensive observability to build safe and predictable applications.</li><li><strong>Security</strong>: LLMs are susceptible to injection attacks, necessitating safeguards to build secure applications that do not leak user information or secrets.</li><li><strong>Performance</strong>: LLMs are expensive to invoke and highly sensitive to prompt variation, requiring efficient function management to reduce context tokens and improve performance.</li><li><strong>Efficiency</strong>: The implementations of tools in chatbots or agents have to be written from scratch by the developers, needing to create the function definitions for the LLM, but also the function execution against an API or a Database.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="acorn-agent-framework">Acorn Agent Framework<a href="#acorn-agent-framework" class="hash-link" aria-label="Direct link to Acorn Agent Framework" title="Direct link to Acorn Agent Framework">​</a></h2><img loading="lazy" src="/img/generic/acorn_overview.png" alt="Acorn Agent Overview" width="100%" class="img_ev3q"><p>Acorn Agent is a framework for building LLM-powered applications through tooling. It provides the necessary infrastructure to instrument LLMs with custom tools, addressing challenges related to safety, security, performance, and efficiency:</p><ul><li><strong>Safety</strong>: The framework validates function calls and supports auto-retry of invalid function invocations. It enables quick iteration of function definitions to improve accuracy and performance.</li><li><strong>Security</strong>: The framework sandboxes function calls through a defined &quot;context,&quot; which includes sensitive function arguments (e.g., userid, sessionid, tokens) that are handled by the framework and not exposed to the LLM call stack.</li><li><strong>Performance</strong>: The framework gives developers full control over the context window construction to optimize cost and performance.</li><li><strong>Efficiency</strong>: The framework provides abstraction layers for managing tooling across many popular LLMs through a standard interface which reduces boilerplate code and custom instrumentation logic. while giving developers full control over context window constructionAt its core, Acorn Agent is a repository of tools that instruments and executes tools for LLMs using a JSON configuration format for semantic annotations, execution logic, and security context.</li></ul><p>Additionally, Acorn Agent facilitates seamless integration of APIs, databases, libraries, and UI frontends as tooling for LLMs. Acorn Agent supports three types of tools:</p><ul><li><strong>API</strong>: Invokes an external system through an API to retrieve information or trigger an action. The framework supports GraphQL, REST, and JDBC, giving the LLM access to internal microservices, external web services, databases, search engines, ERP systems, and more.</li><li><strong>Local</strong>: Invokes a local function to execute a library method or computation. This enables the LLM to execute mathematical or other computations where accuracy and determinism are important.</li><li><strong>Client</strong>: Forwards the tool call to the client or frontend to trigger a UI update, implemented as a function callback in JavaScript. This allows the LLM to customize the presentation of information to the user.</li></ul><p>The Acorn Agent framework is open-source under the Apache 2.0 license. You can view the full source code, download it, and contribute to the project on <a href="https://github.com/DataSQRL/Acorn/" target="_blank" rel="noopener noreferrer">Github</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="example-llm-application">Example LLM Application<a href="#example-llm-application" class="hash-link" aria-label="Direct link to Example LLM Application" title="Direct link to Example LLM Application">​</a></h2><p>To illustrate how the Acorn Agent framework works, consider building an LLM application providing a natural language interface for an online garden store. This application uses the same GraphQL API that the web application uses to place and retrieve customer orders. Additionally, it implements functions for unit conversions and React components on the frontend to display order status.
With Acorn Agent, we can register all of these as tools within the framework, configure an LLM (such as OpenAI’s GPT, Llama3 on AWS Bedrock, or Google Gemini), and set up our system prompt for a friendly shopping assistant.
When a user issues a request, the Acorn Agent framework manages the tools for the LLM.</p><img loading="lazy" src="/img/generic/acorn_call_diagram.png" alt="Acorn Agent Example Instrumentation" width="100%" class="img_ev3q"><p>For example, suppose the user requests: &quot;Order me fertilizer for 3 plots of lawn: 10x20 ft, 50x15 ft, and 30x35 ft. The same fertilizer I ordered last time.&quot;
Acorn Agent injects the relevant tool definitions into the context and hands it to the LLM. The LLM processes the request and calls tools as follows:</p><ul><li><strong>Look up the last orders</strong> for the fertilizer product ID and weight. Acorn Agent augments secure information from the user session, invokes the GraphQL API to retrieve the user’s last orders, and returns the information to the LLM. The LLM identifies which order was for fertilizer as well as the associated product id and weight.</li><li><strong>Convert the given measurements</strong> to total square footage and compute the number of bags needed for the fertilizer product based on the retrieved weight. Acorn Agent executes that tool by invoking a local function that implements the math and conversion. It then returns the number of bags to the LLM.</li><li><strong>Place the order</strong> for the computed number of fertilizer bags and retrieved product ID. Acorn Agent invokes the GraphQL API to place the order within the secure sandbox of the user session. The order details are returned to the LLM.</li><li><strong>Update the UI</strong> with the order information. Acorn Agent forwards that client function call with additional context to the UI to update the React component.</li></ul><p>Acorn Agent handles all tool validations, sandboxing, invocations, and result propagations, allowing developers to focus on building tools and optimizing the context window.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="using-acorn-agent-framework">Using Acorn Agent Framework<a href="#using-acorn-agent-framework" class="hash-link" aria-label="Direct link to Using Acorn Agent Framework" title="Direct link to Using Acorn Agent Framework">​</a></h2><p>To experiment with Acorn Agent as a natural language interface for an existing API or database, you need only write tools and a configuration file—no coding required. Check out the <a href="https://github.com/DataSQRL/Acorn/tree/main/examples" target="_blank" rel="noopener noreferrer">examples</a> for public APIs to get started.
To build an LLM microservice or web application, you can include the Acorn Agent framework as a dependency in your Java, Scala, or Kotlin project. See the <a href="https://github.com/DataSQRL/Acorn/tree/main/java" target="_blank" rel="noopener noreferrer">documentation</a> for all the details. As an example, refer to the <a href="https://github.com/DataSQRL/Acorn/tree/main/java/acorn-spring" target="_blank" rel="noopener noreferrer">Spring Boot application</a> using Acorn Agent to implement a ChatBot.
If you have any questions, feedback, or would like to contribute, please join us on <a href="https://join.slack.com/t/datasqrlcommunity/shared_invite/zt-2l3rl1g6o-im6YXYCqU7t55CNaHqz_Kg" target="_blank" rel="noopener noreferrer">Slack</a>.
Currently, the Acorn Agent framework is limited to the JVM. We aim to support other programming environments soon.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2><p>Building natural language interfaces for user facing applications requires instrumenting LLMs with custom tooling. The open-source Acorn Agent framework provides the infrastructure to manage custom tooling for LLMs and ensures that application is safe, secure, and efficient.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/launch/">launch</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Unfortunately, my semi-retirement has come to an end."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/canz-joins-datasqrl/">Canz Joins DataSQRL</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-01-22T00:00:00.000Z" itemprop="datePublished">January 22, 2024</time> · <!-- -->3 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/canz" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/canz1.png" alt="Michael Canzoneri" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/canz" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Michael Canzoneri</span></a></div><small class="avatar__subtitle" itemprop="description">Head of GTM at DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Unfortunately, my semi-retirement has come to an end.</p><p>It’s been an incredible ten months waking up and not having to be anywhere other than school dropoff.  However, all good things must turn into even better things!</p><p>I’m happy to announce that I’ve joined my old friends from DataStax, <a href="https://www.linkedin.com/in/matthiasbroecheler/" target="_blank" rel="noopener noreferrer">Matthias Broecheler</a>, and <a href="https://www.linkedin.com/in/daniel-henneberger-8721a5155/" target="_blank" rel="noopener noreferrer">Daniel Henneberger</a>, as co-founder of <a href="https://www.datasqrl.com" target="_blank" rel="noopener noreferrer">DataSQRL</a>.</p><p>And what a time to join! Our self-funded venture is already profitable, with a growing customer base.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-does-datasqrl-do">What does <a href="https://www.datasqrl.com" target="_blank" rel="noopener noreferrer">DataSQRL</a> do?<a href="#what-does-datasqrl-do" class="hash-link" aria-label="Direct link to what-does-datasqrl-do" title="Direct link to what-does-datasqrl-do">​</a></h2><p>Your “<strong><em>Operating System for Data</em></strong>” builds data products in <strong><em>minutes</em></strong>.  Gone are months wasted attempting to integrate multiple vendor technologies for a data pipeline.</p><p>DataSQRL abstracts and automates the building of data pipelines through our SQL interface, which we’ve affectionately dubbed SQRL.  Yes, pronounced “Squirrel,” just like the fuzzy little guys running around your yard.</p><p>Have you struggled with Apache Kafka?  Flink?  Streaming?  Data in motion? Integrating your Artificial Intelligence into your systems?  Anything “Real-Time?” Struggle no more, and <a href="https://www.datasqrl.com/docs/getting-started/getting-started/" target="_blank" rel="noopener noreferrer">get started here!</a></p><p>We provide an open-source tool that can help you along with some professional services.</p><p>Now that <em>that</em> is out of the way, onto more interesting things…</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-did-i-do-over-these-last-ten-months-youre-wondering">What did I do over these last ten months? You’re wondering…<a href="#what-did-i-do-over-these-last-ten-months-youre-wondering" class="hash-link" aria-label="Direct link to What did I do over these last ten months? You’re wondering…" title="Direct link to What did I do over these last ten months? You’re wondering…">​</a></h2><p>What <em>didn’t</em> I do?  I…</p><ul><li>Spent a ton of time watching my autistic son make incredible progress</li><li>Helped produce a shark documentary, <a href="https://www.imdb.com/title/tt15475848/?ref_=tt_mv_close" target="_blank" rel="noopener noreferrer">Unmasking Monsters Below</a>, with my friend, Kevin Lapsley</li><li>Traveled to more than 30 different places, both nationally and internationally (pictures below)</li><li>Read 41 books</li><li>Wrote 200 pages in my journal</li><li>Started writing a new book</li><li>Started writing a new screenplay</li><li>Continued working on my photography skills</li><li>Watched SO MUCH college football (We are!)</li><li>Cooked my wife breakfast (almost) every day</li><li>Made a ton of new recipes</li><li>Worked out 4-6 days per week</li><li>Mentored several young professionals to find their way</li><li>Caught up with some old friends</li><li>Served as an advisor to ten AI-based startups</li><li>And attended a few concerts…</li></ul><p>More on all of this as the months roll on…</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-next-for-me-and-datasqrl">What’s next for me and DataSQRL?<a href="#whats-next-for-me-and-datasqrl" class="hash-link" aria-label="Direct link to What’s next for me and DataSQRL?" title="Direct link to What’s next for me and DataSQRL?">​</a></h2><p>If you’re attending <a href="https://datadaytexas.com/" target="_blank" rel="noopener noreferrer">Data Days</a> in Austin, TX, next week, check out Matthias’ presentation.</p><p>Otherwise, make sure you follow us <a href="https://www.linkedin.com/company/datasqrl/" target="_blank" rel="noopener noreferrer">here on LinkedIn</a>.</p><p>I promise that some of my upcoming posts will cover what I did over the last ten months.  You know me… However, here are some highlights in pictures…</p><p><strong><em>A 3x Silicon Valley Unicorn veteran with IPO experience, award-winning screenwriter, and 2006 Time Magazine “Person of the Year,” Canz is often mistaken for Joe Rogan while walking down the street.  He can be found on <a href="https://www.linkedin.com/in/canz/" target="_blank" rel="noopener noreferrer">LinkedIn</a>, <a href="https://www.imdb.com/name/nm3376659/?ref_=fn_al_nm_1" target="_blank" rel="noopener noreferrer">IMDB</a>, and helping people how to pronounce “Conshohocken.”</em></strong></p><p>#autism #journaling #imdb #joerogan #movies #metallica #concerts</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="picture-highlights">Picture Highlights<a href="#picture-highlights" class="hash-link" aria-label="Direct link to Picture Highlights" title="Direct link to Picture Highlights">​</a></h2><img loading="lazy" src="/img/blog/canz-joins/img1.jpg" alt="Highlights |" width="100%" class="img_ev3q"><p>Innescron, County Sligo, Ireland</p><img loading="lazy" src="/img/blog/canz-joins/img2.jpg" alt="Highlights |" width="100%" class="img_ev3q"><p>Mystic, CT</p><img loading="lazy" src="/img/blog/canz-joins/img3.jpg" alt="Highlights |" width="100%" class="img_ev3q"><p>Innescron, County Sligo, Ireland</p><img loading="lazy" src="/img/blog/canz-joins/img4.jpg" alt="Highlights |" width="100%" class="img_ev3q">Newport, RI<img loading="lazy" src="/img/blog/canz-joins/img5.jpeg" alt="Highlights |" width="100%" class="img_ev3q">Metlife Stadium, NJ - Metallica Concert<img loading="lazy" src="/img/blog/canz-joins/img6.jpg" alt="Highlights |" width="100%" class="img_ev3q">Napa Valley, CA</div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/launch/">launch</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="A common problem in search is ordering large result sets. Consider a user searching for “jacket” on an e-commerce platform. How do we order the large number of results to show the most relevant products first? In other words, what kind of jackets is the user looking for? Suit jackets, sport jackets, winter jackets?"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/personalized-ai-search/">Personalized AI Search with Vector Embeddings for Semantic Profiles</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-11-20T00:00:00.000Z" itemprop="datePublished">November 20, 2023</time> · <!-- -->10 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>A common problem in search is ordering large result sets. Consider a user searching for “jacket” on an e-commerce platform. How do we order the large number of results to show the most relevant products first? In other words, what kind of jackets is the user looking for? Suit jackets, sport jackets, winter jackets?</p><p>Often, we have the context to infer what kind of jacket a user is looking for based on their interactions on the site. For example, if a user has men’s running shoes in their shopping cart, they are likely looking for men’s sports jackets when they search for “jacket”.</p><p>At least to a human that seems pretty obvious. Yet, Amazon will return a somewhat random assortment of jackets in this scenario as shown in the screenshot below.</p><img loading="lazy" src="/img/blog/ai_personalized_search_screenshot.png" alt="Amazon search results for `jacket` |" width="100%" class="img_ev3q"><p>To humans the semantic association between “running shoes” and “sport jackets” is natural, but for machines making such associations has been a challenge.
With recent advances in large-language models (LLMs) computers can now compute semantic similarities with high accuracy.</p><p>We are going to use LLMs to compute the semantic context of past user interactions via vector embeddings, aggregate them into a semantic profile, and then use the semantic profile to order search results by their semantic similarity to a user’s profile.</p><p>In other words, we are going to rank search results by their semantic similarity to the things a user has been browsing. That gives us the context we are missing when the user enters a search query.</p><p>In this article, you will learn how to build a personalized shopping search with semantic vector embeddings step-by-step. You can apply the techniques in this article to any kind of search where a user can browse and search a collection of items: event search, knowledge bases, content search, etc.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ai/">AI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/kafka/">Kafka</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink/">Flink</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/postgres/">Postgres</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/search/">search</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/personalization/">personalization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-sqrl/">DataSQRL</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Personalized AI Search with Vector Embeddings for Semantic Profiles" href="/blog/personalized-ai-search/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Let’s build a personalized recommendation engine using AI as an event-driven microservice with Kafka, Flink, and Postgres. And since Current23 is starting soon, we will use the events of this event-driven conference as our input data (sorry for the pun). You’ll learn how to apply AI techniques to streaming data and what talks you want to attend at the Kafka conference - double win!"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/recommendations-current23/">Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-09-21T00:00:00.000Z" itemprop="datePublished">September 21, 2023</time> · <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Let’s build a personalized recommendation engine using AI as an event-driven microservice with Kafka, Flink, and Postgres. And since Current23 is starting soon, we will use the events of this event-driven conference as our input data (sorry for the pun). You’ll learn how to apply AI techniques to streaming data and what talks you want to attend at the Kafka conference - double win!</p><div style="float:right;width:40%"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/gI_TRF1z-So" title="DataSQRL Introduction" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p>We will implement the whole microservice in 50 lines of code thanks to the DataSQRL compiler, which eliminates all the data plumbing so we can focus on building.</p><p>Watch the video to see the microservice in action or read below for step-by-step building instructions and details.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-we-will-build">What We Will Build<a href="#what-we-will-build" class="hash-link" aria-label="Direct link to What We Will Build" title="Direct link to What We Will Build">​</a></h2><p>We are going to build a recommendation engine and semantic search that uses AI to provide personalized results for users based on user interactions.</p><p>Let’s break that down:
Our input data is a stream of conference events, namely the talks with title, abstract, speakers, time, and so forth. We consume this data from an external data source.</p><p>In addition, our microservice has endpoints to capture which talks a user has liked and what interests a user has expressed. We use those user interactions to create a semantic user profile for personalized recommendations and personalized search results.</p><p>We create the semantic user profile through vector embeddings, an AI technique for mapping text to numbers in a way that preserves the content of the text for comparison. It’s a great tool for representing the meaning of text in a computable way. It&#x27;s like mapping addresses (i.e. street, city, zip, country) onto geo-coordinates. It’s hard to compare two addresses, but easy to compute the distance between two geo-coordinates. Vector embeddings do the same thing for natural language text.</p><p>Those semantic profiles are then used to serve recommendations and personalized search results.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ai/">AI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/kafka/">Kafka</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink/">Flink</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/postgres/">Postgres</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/microservice/">microservice</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-sqrl/">DataSQRL</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Personalized Recommendations for Current23 with Vector Embeddings in Flink and Kafka" href="/blog/recommendations-current23/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="When developing streaming applications or event-driven microservices, you face the decision of whether to preprocess data transformations in the stream engine or execute them as queries against the database at request time. The choice impacts your application’s performance, behavior, and cost. An incorrect decision results in unnecessary work and potential application failure."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/preprocess-or-query/">To Preprocess or to Query, that’s the Question!</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-08-15T00:00:00.000Z" itemprop="datePublished">August 15, 2023</time> · <!-- -->14 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>When developing streaming applications or event-driven microservices, you face the decision of whether to preprocess data transformations in the stream engine or execute them as queries against the database at request time. The choice impacts your application’s performance, behavior, and cost. An incorrect decision results in unnecessary work and potential application failure.</p><img loading="lazy" src="/img/blog/preprocessOrQuery.png" alt="To preprocess or to query? &gt;|" width="50%" class="img_ev3q"><p>In this article, we’ll delve into the tradeoff between preprocessing and querying, guiding you to make the right decision. We’ll also introduce tools to simplify this process. Plus, you’ll learn how building streaming applications is related to fine cuisine. It’ll be a fun journey through the land of stream processing and database querying. Let’s go!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="recap-anatomy-of-a-streaming-application">Recap: Anatomy of a Streaming Application<a href="#recap-anatomy-of-a-streaming-application" class="hash-link" aria-label="Direct link to Recap: Anatomy of a Streaming Application" title="Direct link to Recap: Anatomy of a Streaming Application">​</a></h2><p>If you&#x27;re in the process of building an event-driven microservice or streaming application, let&#x27;s recap what that entails. An event-driven microservice consumes data from one or multiple data streams, processes the data, writes the results to a data store, and exposes the final data through an API for external users to access.</p><p>The figure below visualizes the high-level architecture of a streaming application and its components: data streams (e.g. Kafka), stream processor (e.g. Flink), database (e.g. Postgres), and API server (e.g. GraphQL server).</p><img loading="lazy" src="/img/blog/dataflow-stages.svg" alt="Streaming Application Architecture" width="100%" class="img_ev3q"><p>An actual event-driven microservice might have a more intricate architecture, but it will always include these four elements: a system for managing data streams, an engine for processing streaming data, a place to store the results, and a server to expose the service endpoint.</p><p>This means an event-driven architecture has two stages: the preprocess stage, which processes data as it streams in, and the query stage which processes user requests against the API. Each stage handles data, but they differ in what triggers the processing: incoming data triggers the preprocess stage, while user requests trigger the query stage. The preprocess stage handles data before the user needs it, and the query stage handles data when the user explicitly requests it.</p><p>Understanding these two stages is vital for the successful implementation of event-driven microservices. Unlike most web services with only a query stage or data pipelines with only a preprocess stage, event-driven microservices require a combination of both stages.</p><p>This leads to the question: Where should data transformations be processed? In the preprocessing stage or the query stage? And what’s the difference, anyways? That’s what we will be investigating in this article.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/kafka/">Kafka</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink/">Flink</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/postgres/">Postgres</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-pipeline/">data pipeline</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-sqrl/">DataSQRL</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about To Preprocess or to Query, that’s the Question!" href="/blog/preprocess-or-query/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Stream processing technologies like Apache Flink introduce a new type of data transformation that’s very powerful: the temporal join. Temporal joins add context to data streams while being efficient and fast to execute."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/temporal-join/">Why Temporal Join is Stream Processing’s Superpower</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-07-10T00:00:00.000Z" itemprop="datePublished">July 10, 2023</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Stream processing technologies like Apache Flink introduce a new type of data transformation that’s very powerful: the temporal join. Temporal joins add context to data streams while being efficient and fast to execute.</p><img loading="lazy" src="/img/dev/temporal_join.svg" alt="Temporal Join &gt;" width="30%" class="img_ev3q"><p>This article introduces the temporal join, compares it to the traditional inner join, explains when to use it, and why it is a secret superpower.</p><p>Table of Contents:</p><ul><li><a href="#review">The Join: A Quick Review</a></li><li><a href="#tempjoin">The Temporal Join: Linking Stream and State</a></li><li><a href="#tempinner">Temporal Join vs Inner Join</a></li><li><a href="#efficient">Why Temporal Joins are Fast and Efficient</a></li><li><a href="#easy">Temporal Joins Made Easy to Use</a></li><li><a href="#summary">Summary</a></li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/join/">Join</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink/">Flink</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-sqrl/">DataSQRL</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Why Temporal Join is Stream Processing’s Superpower" href="/blog/temporal-join/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="In the world of data-driven applications, Apache Flink is a powerful tool that transforms streams of raw data into valuable results. But how do you make these results accessible to users, customers, or consumers of your application? Most often, we found the answer to that question was: GraphQL. GraphQL gives users a flexible way to query for data, makes it easy to ingest events, and supports pushing data updates to the user in real-time."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/flink-graphql-peanut-butter-jelly/">Why Apache Flink and GraphQL Are like Peanut Butter and Jelly</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-06-27T00:00:00.000Z" itemprop="datePublished">June 27, 2023</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>In the world of data-driven applications, Apache Flink is a powerful tool that transforms streams of raw data into valuable results. But how do you make these results accessible to users, customers, or consumers of your application? Most often, we found the answer to that question was: GraphQL. GraphQL gives users a flexible way to query for data, makes it easy to ingest events, and supports pushing data updates to the user in real-time.</p><img loading="lazy" src="/img/blog/flink_graphql.svg" alt="Flink hearts GraphQL &gt;" width="40%" class="img_ev3q"><p>In this blog post, we’ll discuss what GraphQL is and why it is a good fit for Flink applications. Like peanut butter and jelly, Flink and GraphQL don’t seem related but the combination is surprisingly good.</p><p>Table of Contents:</p><ul><li><a href="#access">How To Access Flink Results?</a></li><li><a href="#graphql">What is GraphQL?</a></li><li><a href="#benefit1">Benefit #1: Flexible Access for Data APIs</a></li><li><a href="#benefit2">Benefit #2: Realtime Data Updates with GraphQL Subscriptions</a></li><li><a href="#benefit3">Benefit #3: Simplify Event Ingestion with GraphQL Mutations</a></li><li><a href="#downsides">Downsides of using GraphQL in Flink Applications</a></li><li><a href="#howto">How to Build GraphQL APIs with Flink</a></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="access">How To Access Flink Results?<a href="#access" class="hash-link" aria-label="Direct link to How To Access Flink Results?" title="Direct link to How To Access Flink Results?">​</a></h2><p>Quick background before we dive into the details. <a href="https://flink.apache.org/" target="_blank" rel="noopener noreferrer">Apache Flink</a> is a scalable stream processor that can ingest data from multiple sources, integrate, transform, and analyze the data, and produce results in real time. Apache Flink is the brain of your data processing operations.</p><img loading="lazy" src="/img/external/flink_logo.svg" alt="Flink Logo &gt;" width="30%" class="img_ev3q"><p>But Apache Flink cannot make the processed results accessible to users of your application. Flink has an API, but that API is only for administering and monitoring Flink jobs. It doesn’t give outside users access to the result data. In other words, Flink is a brain without a mouth to communicate results externally.</p><p>To make results accessible, you have to write them somewhere and expose them through an interface. But how? We have built a number of Flink applications and in most cases, the answer was: write the results to a database or Kafka and expose them through an API. Over the years, our default choice for the API has become GraphQL. Here’s why.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/graph-ql/">GraphQL</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink/">Flink</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-sqrl/">DataSQRL</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Why Apache Flink and GraphQL Are like Peanut Butter and Jelly" href="/blog/flink-graphql-peanut-butter-jelly/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Apache Flink is an incredibly powerful stream processor. But to build a complete application with Flink you need to integrate multiple complex technologies which requires a significant amount of custom code."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/simplifying-flink-app-development/">Simplifying Apache Flink Application Development with DataSQRL</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-06-21T00:00:00.000Z" itemprop="datePublished">June 21, 2023</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Apache Flink is an incredibly powerful stream processor. But to build a complete application with Flink you need to integrate multiple complex technologies which requires a significant amount of custom code.
DataSQRL is an open-source tool that simplifies this process by compiling SQL into a data pipeline that integrates Flink, Kafka, Postgres, and API layer. </p><div style="float:right;width:40%"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/mf5q-IdbVQY" title="DataSQRL Introduction" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p>DataSQRL allows you to focus on your application logic without getting bogged down in the details of how to execute your data transformations efficiently across multiple technologies.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-challenge-of-building-applications-with-flink">The Challenge of Building Applications with Flink<a href="#the-challenge-of-building-applications-with-flink" class="hash-link" aria-label="Direct link to The Challenge of Building Applications with Flink" title="Direct link to The Challenge of Building Applications with Flink">​</a></h2><p>We have built several applications in Flink: recommendation engines, data mesh endpoints, monitoring dashboards, Customer 360 APIs, smart IoT apps, and more. Across those use cases, Flink proved to be versatile and powerful in its ability to instantly analyze and aggregate data from multiple sources. But we found it quite difficult and time-consuming to build applications with Flink.</p><img loading="lazy" src="/img/reference/compiledMicroservice.svg" alt="DataSQRL compiled data pipeline &gt;" width="50%" class="img_ev3q"><p>To start, you need to learn Flink: the table and datastream API, watermarking, windowing, and all the other stream processing concepts. Flink alone gets our heads spinning. And Flink is just one component of the application.</p><p>To build a complete data pipeline, you need Kafka to hold your streaming data and a database like Postgres to query the processed data. On top, you need an API layer that captures input data and provides access to the processed data. Your team must learn, implement, and integrate multiple complex technologies. It takes a village to build a Flink app.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introducing-datasqrl-a-solution-for-streamlined-flink-development">Introducing DataSQRL: A Solution for Streamlined Flink Development<a href="#introducing-datasqrl-a-solution-for-streamlined-flink-development" class="hash-link" aria-label="Direct link to Introducing DataSQRL: A Solution for Streamlined Flink Development" title="Direct link to Introducing DataSQRL: A Solution for Streamlined Flink Development">​</a></h2><img loading="lazy" src="/img/full_squirrel.svg" alt="DataSQRL &gt;" width="20%" class="img_ev3q"><p>That’s why we built <a href="/">DataSQRL</a>. DataSQRL compiles the SQL that defines your data processing into an integrated data pipeline that orchestrates Flink, Kafka, Postgres, and API - saving us a ton of time and headache in the process. Why not let the computer do all the hard work?</p><p>Let me show you how DataSQRL works by building an IoT monitoring service.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-sqrl/">DataSQRL</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink/">Flink</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Simplifying Apache Flink Application Development with DataSQRL" href="/blog/simplifying-flink-app-development/"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="When creating data-intensive applications or services, your data logic (i.e. the code that defines how to process the data) gets fragmented across multiple data systems, languages, and mental models. This makes data-driven applications difficult to implement and hard to maintain."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/sqrl-high-level-data-language-sql/">SQRL: Enhancing SQL to a High-Level Data Language</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-05-22T00:00:00.000Z" itemprop="datePublished">May 22, 2023</time> · <!-- -->8 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/headshots/matthias1.png" alt="Matthias Broecheler" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/mbroecheler" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Matthias Broecheler</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of DataSQRL</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>When creating data-intensive applications or services, your data logic (i.e. the code that defines how to process the data) gets fragmented across multiple data systems, languages, and mental models. This makes data-driven applications difficult to implement and hard to maintain.</p><p>SQRL is a high-level data programming language that compiles into executables for all your data systems, so you can implement your data logic in one place. SQRL adds support for data streams and relationships to SQL while maintaining its familiar syntax and semantics.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-do-we-need-sqrl">Why Do We Need SQRL?<a href="#why-do-we-need-sqrl" class="hash-link" aria-label="Direct link to Why Do We Need SQRL?" title="Direct link to Why Do We Need SQRL?">​</a></h2><img loading="lazy" src="/img/reference/reactive_data_layer.svg" alt="Data Layer of data-driven application &gt;" width="30%" class="img_ev3q"><p>The data layer of a data-driven application comprises multiple components: There’s the good ol’ database for data storage and queries, a server for handling incoming data and translating API requests into database queries, a queue/log for asynchronous data processing, and a stream processor for pre-processing and writing new data to the database. Consequently, your data processing code becomes fragmented across various systems, technologies, and languages.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/sqrl/">SQRL</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/community/">community</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about SQRL: Enhancing SQL to a High-Level Data Language" href="/blog/sqrl-high-level-data-language-sql/"><b>Read More</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/page/2/"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started/">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/intro/">Documentation Overview</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/reference/introduction/">Reference Docs</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/process/intro/">DataSQRL Process</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/datasqrl" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://join.slack.com/t/datasqrlcommunity/shared_invite/zt-2l3rl1g6o-im6YXYCqU7t55CNaHqz_Kg" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/DataSQRL/sqrl" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/DataSQRL" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">DataSQRL</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/about/">About</a></li><li class="footer__item"><a class="footer__link-item" href="/services/">Services</a></li><li class="footer__item"><a class="footer__link-item" href="/careers/">Careers</a></li><li class="footer__item"><a class="footer__link-item" href="/contact/">Contact Us</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 DataSQRL, Inc.<br><a href="/docs/attribution">Image Attributions</a></div></div></div></footer></div>
<script src="/assets/js/runtime~main.f0548db5.js"></script>
<script src="/assets/js/main.ae18b9cf.js"></script>
</body>
</html>